{
  "name": "Multi_30k_context_GRU",
  "n_gpu": 1,
  "arch": {
    "file": "model.seq2seq.attention",
    "args": {
      "input_dim": 7855,
      "output_dim": 5923,
      "enc_emb_dim": 256,
      "dec_emb_dim": 256,
      "enc_hid_dim": 512,
      "dec_hid_dim": 512,
      "enc_dropout": 0.5,
      "dec_dropout": 0.5
    }
  },
  "data_loader": {
    "type": "LanguageDataLoader",
    "iterator": true,
    "args": {
      "data_dir": "data/multi30k",
      "reverse_src": false,
      "batch_sizes": [
        128,
        128,
        1
      ]
    }
  },
  "optimizer": {
    "type": "Adam",
    "args": {
      "lr": 0.001,
      "weight_decay": 0,
      "amsgrad": true
    }
  },
  "loss": {
    "function": "cross_entropy",
    "padding_idx": true
  },
  "metrics": [],
  "lr_scheduler": {
    "type": "StepLR",
    "args": {
      "step_size": 50,
      "gamma": 0.1
    }
  },
  "trainer": {
    "epochs": 100,
    "save_dir": "saved/",
    "save_period": 1,
    "verbosity": 2,
    "monitor": "min val_loss",
    "early_stop": 10,
    "tensorboard": true
  }
}
